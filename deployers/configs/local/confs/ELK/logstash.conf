input {
    http_poller {
	urls => {
		health => {
			method => get
			user => "elastic"
			password => "changeme"
			url => "http://worker1:9200/_nodes/stats?pretty"
			headers => {
				Accept => "application/json"
			}
		}
	}
	request_timeout => 60
	schedule => { "every" => "30s" }
	codec => "json"
	type => "nodestats"
    }
    kafka {
	auto_offset_reset => "earliest"
	group_id => "elk"
	bootstrap_servers => "kafka1:9092,kafka2:9092,kafka3:9092"
	topics => [ "activities", "records" ]
	type => "data"
    }
}
filter {
  if [type] == "nodestats" {
	mutate {
		add_field => { "filetime" => "%{@timestamp}" }
	}  
	mutate {
		gsub => ["filetime", "[A-Za-z]", " ",
			 "filetime", ":[0-9]{2}\..*", ":00"]
	}  
	grok {
		match => { 
		    "filetime" => ':%{NUMBER:minute:int}:00'
		}
	}
	ruby{
		code => "event.set('minute', 5*(event.get('minute')/5)+5 )"
	}
	grok {
		match => {"filetime" =>'(?<TIMET_hour>.* [0-9]{2})'}	 
	}
	mutate {
		replace => { "filetime" => "%{TIMET_hour}:%{minute}:00" }
		gsub => ["filetime", ":([0-9]):", ":0\1:"]
	}
	mutate {
		gsub => ["filetime", ":", ""]
		update => { "filetime" => "%{filetime} GMT" }
	}
	json {
		source => "message"
	}
  }
	mutate {
		remove_field => [ "message" ]
	}
}
## Add your filters / logstash plugins configuration here

output {
  if [type] == "nodestats" {
	webhdfs {
		host => "master.demo.com"
		codec => "json"
		port => 9870
		user => "vagrant"
		path => "nodestats/%{filetime}"
	}
  }
  if [type] == "data" {
	elasticsearch {
		hosts => "elasticsearch1:9200"
		index => "data-%{+YYYY.MM.dd}"
		user => elastic
		password => changeme
	}
  }
}
